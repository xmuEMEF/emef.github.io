<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="EMEF: Ensemble Multi-Exposure Image Fusion.">
  <meta name="keywords" content="EMEF, Multi-Exposure Fusion, HDR, Image Fusion">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>EMEF</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/assets/logo.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">EMEF: Ensemble Multi-Exposure Image Fusion</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://medalwill.github.io/">Renshuai Liu</a>,</span>
            <span class="author-block">
              Chengyang Li,</span>
            <span class="author-block">
              Haitao Cao,</span>
            <span class="author-block">
              Yinglin Zheng,</span>
            <span class="author-block">
              <a href="https://chengxuan90.github.io/">Xuan Cheng</a><sup>*</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">School of Informatics, Xiamen University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2401.01207"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=BFd1KzA8YN8"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/drive/folders/1CvTM3o25cXK1yoqDbZe4QF4X69lk8uct?usp=drive_link"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Results</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/assets/banner.png">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">DiffSFSR takes three inputs: a prompt describing the background, a selfie photo uploaded by the user, and a text related to the fine-grained expression labels. The generated faces well match the inputted triples and exhibit fine-grained expression synthesis.
      </h2>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <img src="./static/examples/p1.JPG">
        </div>
        <div class="item">
          <img src="./static/examples/p2.JPG">
        </div>
        <div class="item">
          <img src="./static/examples/p3.JPG">
        </div>
        <div class="item">
          <img src="./static/examples/p4.JPG">
        </div>
        <div class="item">
          <img src="./static/examples/p5.JPG">
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In human-centric content generation, the pre-trained text-to-image models struggle to produce user-wanted portrait images, which retain the identity of individuals while exhibiting diverse expressions. 
          </p>
          <p>
            This paper introduces our efforts towards <b>personalized face generation</b>. To this end, we propose a novel multi-modal face generation framework, capable of <b>simultaneous identity-expression control</b> and <b>more fine-grained expression synthesis</b>. Our expression control is so sophisticated that it can be specialized by the fine-grained emotional vocabulary. We devise a novel diffusion model that can undertake the task of simultaneously face swapping and reenactment. Due to the entanglement of identity and expression, it's nontrivial to separately and precisely control them in one framework, thus has not been explored yet. To overcome this, we propose several innovative designs in the conditional diffusion model, including balancing identity and expression encoder, improved midpoint sampling, and explicitly background conditioning. 
          </p>
          <p>
            Extensive experiments have demonstrated the controllability and scalability of the proposed framework, in comparison with state-of-the-art text-to-image, face swapping, and face reenactment methods.
          </p>
          </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/BFd1KzA8YN8?si=2TtCCsileQzNgWHw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Improved Midpoint Sampling</h2>
      </div>
    </div>
         <!-- Qualitative. -->
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h3 class="title is-4">Qualitative</h2>
          <p>
            Here are some cases of sampling results. As shown above, Our results are not only more faithful to ground truth, 
            but also more realistic and clear in the regions of eyes, mouths and even the reflection of sunglasses.
          </p>
          <img src="./static/assets/IMP_quality.png">
        </div>
      </div>
      <!--/ Qualitative. -->

      <!-- Quantitative. -->
      <div class="column">
        <h3 class="title is-4">Quantitative</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              We employ MSE to measure the error between sampling results and ground truth. 
              All sampling methods can decrease the reconstruction errors along with the training steps 
              increasing. Our sampling method can achieve lower MSE than others in all periods.
            </p>
            <img src="./static/assets/IMP_quantity.png">
          </div>

        </div>
      </div>
    </div>
    <!--/ Quantitative. -->

  </div>
</section>





<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @article{liu2024simultaneous,
        title={Towards a Simultaneous and Granular Identity-Expression Control in Personalized Face Generation},
        author={Renshuai Liu and Bowen Ma and Wei Zhang and Zhipeng Hu and Changjie Fan and Tangjie Lv and Yu Ding and Xuan Cheng},
        journal={arXiv preprint arXiv:2401.01207},
        year={2024}
      }
</code></pre>
  </div>
</section>



<footer class="footer">
  <!-- todo -->
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, licensed under a <a
            href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
