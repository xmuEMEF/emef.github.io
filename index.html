<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="EMEF: Ensemble Multi-Exposure Image Fusion.">
  <meta name="keywords" content="EMEF, Multi-Exposure Fusion, HDR, Image Fusion">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>EMEF</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/assets/logo.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">EMEF: Ensemble Multi-Exposure Image Fusion</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://medalwill.github.io/">Renshuai Liu</a>,</span>
            <span class="author-block">
              Chengyang Li,</span>
            <span class="author-block">
              Haitao Cao,</span>
            <span class="author-block">
              Yinglin Zheng,</span>
            <span class="author-block">
              <a href="https://chengxuan90.github.io/">Xuan Cheng</a><sup>*</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">School of Informatics, Xiamen University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://ojs.aaai.org/index.php/AAAI/article/view/25259"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2305.12734"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=s0-XugkkRhI"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/medalwill/EMEF"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/drive/folders/151LaYxeIk9Q0SZS9dVzucWCqiQ4ejhJe"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Results</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/assets/banner.png">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">The proposed EMEF consists of two main stages: (a) pre-train an imitator network, and (b) tune the imitator in the runtime.
        </h2>
    </div>
  </div>
</section>


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <img src="./static/examples/p1.JPG">
        </div>
        <div class="item">
          <img src="./static/examples/p2.JPG">
        </div>
        <div class="item">
          <img src="./static/examples/p3.JPG">
        </div>
        <div class="item">
          <img src="./static/examples/p4.JPG">
        </div>
        <div class="item">
          <img src="./static/examples/p5.JPG">
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Although remarkable progress has been made in recent years, current multi-exposure image fusion (MEF) research is still bounded by the lack of real ground truth, objective evaluation function, and robust fusion strategy.
          </p>
          <p>
            In this paper, we study the MEF problem from a new perspective. We don’t utilize any synthesized ground truth, design any loss function, or develop any fusion strategy. Our proposed method EMEF takes advantage of the wisdom of multiple imperfect MEF contributors including both conventional and deep learning-based methods. Specifically, EMEF consists of two main stages: pre-train an imitator network and tune the imitator in the runtime. In the first stage, we make a unified network imitate different MEF targets in a style modulation way. In the second stage, we tune the imitator network by optimizing the style code, in order to find an optimal fusion result for each input pair. 
          </p>
          <p>
            In the experiment, we construct EMEF from four state-of-the-art MEF methods and then make comparisons with the individuals and several other competitive methods on the latest released MEF benchmark dataset. The promising experimental results demonstrate that our ensemble framework can “get the best of all worlds”. The code is available at https://github.com/medalwill/EMEF.
          </p>
          </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe width="560" height="315" src="https://www.youtube.com/embed/s0-XugkkRhI?si=jv3YjQHl9COcrHwZ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>



<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Improved Midpoint Sampling</h2>
      </div>
    </div>
    
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h3 class="title is-4">Qualitative</h2>
          <p>
            Here are some cases of sampling results. As shown above, Our results are not only more faithful to ground truth, 
            but also more realistic and clear in the regions of eyes, mouths and even the reflection of sunglasses.
          </p>
          <img src="./static/assets/IMP_quality.png">
        </div>
      </div>

      
      <div class="column">
        <h3 class="title is-4">Quantitative</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              We employ MSE to measure the error between sampling results and ground truth. 
              All sampling methods can decrease the reconstruction errors along with the training steps 
              increasing. Our sampling method can achieve lower MSE than others in all periods.
            </p>
            <img src="./static/assets/IMP_quantity.png">
          </div>

        </div>
      </div>
    </div>
    

  </div>
</section> -->





<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @article{liu2023emef,
        title={EMEF: Ensemble Multi-Exposure Image Fusion},
        volume={37}, 
        url={https://ojs.aaai.org/index.php/AAAI/article/view/25259}, 
        DOI={10.1609/aaai.v37i2.25259}, 
        number={2}, 
        journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
        author={Liu, Renshuai and Li, Chengyang and Cao, Haitao and Zheng, Yinglin and Zeng, Ming and Cheng, Xuan}, 
        year={2023}, 
        month={Jun.}, 
        pages={1710-1718} 
      }
</code></pre>
  </div>
</section>



<footer class="footer">
  <!-- todo -->
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, licensed under a <a
            href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
